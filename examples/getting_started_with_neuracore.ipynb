{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NeuracoreAI/neuracore/blob/docs/colab-notebook-bigym/examples/getting_started_with_neuracore.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVsqoS3A-O5A"
      },
      "source": [
        "# ü§ñ **Getting started with Neuracore**\n",
        "\n",
        "This guide walks you step-by-step through collecting robot demonstration data in simulation and streaming it to **Neuracore** for storage, visualization, model training, and deployment.\n",
        "\n",
        "In particular, you will use the [Bigym](https://github.com/NeuracoreAI/bigym/) simulation benchmark (MuJoCo-based) with a Unitree H1 humanoid, replay expert actions, and record joint states and camera images to your Neuracore account.\n",
        "\n",
        "Run the cells in order from top to bottom. You can watch your robot and collected data appear in the [Neuracore dashboard](https://www.neuracore.com/) as you go.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step-by-step guide for data collection, visualization, model training and deployment:**\n",
        "1. **Log in** to Neuracore and use the Python client to talk to the Neuracore API.\n",
        "2. **Register a robot** with Neuracore by providing an MJCF model, and see it show up on the **Robots** page and in the dashboard overview.\n",
        "3. **Create a dataset** in Neuracore and find it on the **Data** page.\n",
        "4. **Run episodes** in one of Bigym simulation environments by replaying expert actions.\n",
        "5. **Record and upload data**: record episodes on Neuracore with `nc.start_recording()`, and visualize logged data on the web dashboard.\n",
        "6. **Retrieve a previously collected dataset** on a Python client with `nc.get_dataset()` and `dataset.synchronize()`\n",
        "7. **Train and deploy models** on your dataset using the web dashboard or the Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6iKnwYaBWsG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Installing dependencies**\n",
        "#@markdown - Neuracore from PyPI\n",
        "#@markdown - Bigym from GitHub\n",
        "#@markdown\n",
        "#@markdown This may take a few minutes.\n",
        "\n",
        "# Installing neuracore\n",
        "!pip install neuracore==7.14.1 > /dev/null 2>&1\n",
        "\n",
        "# Installing rust --- Why? Safetensors 0.3.3 (required by Bigym) has no pre-built wheel on Colab, therefore it builds from source. That needs Rust.\n",
        "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y -q > /dev/null 2>&1\n",
        "import os\n",
        "os.environ[\"PATH\"] = os.path.expanduser(\"~/.cargo/bin\") + os.pathsep + os.environ.get(\"PATH\", \"\")\n",
        "\n",
        "# Installing bigym --- Commit at the time of creation: 79420b0abad6fa7d7dfd98569cb485f73a2c8e3b\n",
        "!git clone https://github.com/NeuracoreAI/bigym.git /content/bigym > /dev/null 2>&1\n",
        "!pip install -e /content/bigym > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43IrqfxO2ip1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown ### **Restart runtime session**\n",
        "# @markdown After installing dependencies, restart your runtime session via **Runtime** > **Restart session** (CTRL+M .)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OlAX7IhiBWsH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown ### **Imports**\n",
        "# @markdown **Troubleshooting**: if you get import errors, make you sure you \"Restart runtime session\" after pip installing everything above. See cell above or press \"CTRL+M .\"\n",
        "\n",
        "import os\n",
        "# Headless OpenGL for Colab (no display server)\n",
        "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
        "\n",
        "import zipfile\n",
        "import gdown\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import neuracore as nc\n",
        "import bigym\n",
        "from demonstrations.demo_store import DemoStore\n",
        "from demonstrations.utils import Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ8kUIi7BWsH"
      },
      "outputs": [],
      "source": [
        "# @markdown ### **Configuration and utils**\n",
        "# @markdown Load Bigym helpers (joint names, observation converters, headless make_env).\n",
        "\n",
        "# Bigym env config\n",
        "from bigym.action_modes import JointPositionActionMode\n",
        "from bigym.envs.reach_target import ReachTarget\n",
        "from bigym.utils.observation_config import CameraConfig, ObservationConfig\n",
        "\n",
        "FREQUENCY = 20\n",
        "DT = 1.0 / FREQUENCY\n",
        "\n",
        "JOINT_NAMES = [\n",
        "    \"left_shoulder_pitch\",\n",
        "    \"left_shoulder_roll\",\n",
        "    \"left_shoulder_yaw\",\n",
        "    \"left_elbow\",\n",
        "    \"right_driver_joint\",\n",
        "    \"right_coupler_joint\",\n",
        "    \"right_spring_link_joint\",\n",
        "    \"right_follower_joint\",\n",
        "    \"left_driver_joint\",\n",
        "    \"left_coupler_joint\",\n",
        "    \"left_spring_link_joint\",\n",
        "    \"left_follower_joint\",\n",
        "    \"left_wrist\",\n",
        "    \"right_shoulder_pitch\",\n",
        "    \"right_shoulder_roll\",\n",
        "    \"right_shoulder_yaw\",\n",
        "    \"right_elbow\",\n",
        "    \"right_driver_joint\",\n",
        "    \"right_coupler_joint\",\n",
        "    \"right_spring_link_joint\",\n",
        "    \"right_follower_joint\",\n",
        "    \"left_driver_joint\",\n",
        "    \"left_coupler_joint\",\n",
        "    \"left_spring_link_joint\",\n",
        "    \"left_follower_joint\",\n",
        "    \"right_wrist\",\n",
        "    \"pelvis_x\",\n",
        "    \"pelvis_y\",\n",
        "    \"pelvis_rz\",\n",
        "    \"h1_floating_base\",\n",
        "]\n",
        "JOINT_ACTUATORS = [\n",
        "    \"floating_base_x\",\n",
        "    \"floating_base_y\",\n",
        "    \"floating_base_z\",\n",
        "    \"left_shoulder_pitch\",\n",
        "    \"left_shoulder_roll\",\n",
        "    \"left_shoulder_yaw\",\n",
        "    \"left_elbow\",\n",
        "    \"left_wrist\",\n",
        "    \"right_shoulder_pitch\",\n",
        "    \"right_shoulder_roll\",\n",
        "    \"right_shoulder_yaw\",\n",
        "    \"right_elbow\",\n",
        "    \"right_wrist\",\n",
        "    \"gripper_left\",\n",
        "    \"gripper_right\",\n",
        "]\n",
        "\n",
        "\n",
        "def obs_to_joint_dict(obs, joint_names):\n",
        "    \"\"\"Proprioception to joint position/velocity dicts (qpos..., qvel...).\"\"\"\n",
        "    p = obs[\"proprioception\"].astype(float)\n",
        "    mid = len(p) // 2\n",
        "    qpos = dict(zip(joint_names, p[:mid]))\n",
        "    qvel = dict(zip(joint_names, p[mid:]))\n",
        "    return qpos, qvel\n",
        "\n",
        "\n",
        "def obs_to_imgs(obs):\n",
        "    \"\"\"Extract camera images from observation (CHW -> HWC).\"\"\"\n",
        "    return {\n",
        "        \"head\": obs[\"rgb_head\"].transpose(1, 2, 0),\n",
        "        \"left_wrist\": obs[\"rgb_left_wrist\"].transpose(1, 2, 0),\n",
        "        \"right_wrist\": obs[\"rgb_right_wrist\"].transpose(1, 2, 0),\n",
        "    }\n",
        "\n",
        "\n",
        "def action_to_joint_action_dict(action, joint_names):\n",
        "    \"\"\"Convert action array to joint position dict.\"\"\"\n",
        "    return dict(zip(joint_names, action))\n",
        "\n",
        "\n",
        "def make_env():\n",
        "    \"\"\"ReachTarget env with render_mode='rgb_array' for headless Colab.\"\"\"\n",
        "    return ReachTarget(\n",
        "        action_mode=JointPositionActionMode(floating_base=True, absolute=True),\n",
        "        observation_config=ObservationConfig(\n",
        "            cameras=[\n",
        "                CameraConfig(\"head\", resolution=(84, 84)),\n",
        "                CameraConfig(\"left_wrist\", resolution=(84, 84)),\n",
        "                CameraConfig(\"right_wrist\", resolution=(84, 84)),\n",
        "            ]\n",
        "        ),\n",
        "        control_frequency=FREQUENCY,\n",
        "        render_mode=\"rgb_array\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcYMaBxwBWsH"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Utility function to run one episode**\n",
        "#@markdown Function to run a single episode on the ReachTarget Bigym environment by replaying expert actions and log the data to Neuracore.\n",
        "\n",
        "def run_episode(\n",
        "    episode_idx: int,\n",
        "    record: bool,\n",
        "    demo_store: DemoStore,\n",
        ") -> bool:\n",
        "    \"\"\"Run one demonstration episode and optionally record it.\"\"\"\n",
        "    print(f\"\\n=== Starting Episode {episode_idx} ===\")\n",
        "\n",
        "    env = make_env()\n",
        "    metadata = Metadata.from_env(env)\n",
        "\n",
        "    demo = demo_store.get_demos(metadata, amount=1, frequency=FREQUENCY)[0]\n",
        "\n",
        "    obs, info = env.reset(seed=demo.seed)\n",
        "    success = False\n",
        "    t = time.time()\n",
        "\n",
        "    try:\n",
        "        if record:\n",
        "            nc.start_recording()\n",
        "\n",
        "        nc.log_custom_1d(\"my_custom_data\", np.array([1, 2, 3, 4, 5]), timestamp=t)\n",
        "        qpos, qvel = obs_to_joint_dict(obs, JOINT_NAMES)\n",
        "        nc.log_joint_positions(qpos, timestamp=t)\n",
        "        nc.log_joint_velocities(qvel, timestamp=t)\n",
        "        images = obs_to_imgs(obs)\n",
        "        nc.log_rgb(\"head\", images[\"head\"], timestamp=t)\n",
        "        nc.log_language(\n",
        "            \"instruction\",\n",
        "            \"Move two plates simultaneously from one draining rack to the other.\",\n",
        "            timestamp=t,\n",
        "        )\n",
        "\n",
        "        for step in demo._steps:\n",
        "            obs, reward, terminated, truncated, info = env.step(step.info[\"demo_action\"])\n",
        "            print(f\"Reward={reward}, terminated={terminated}, truncated={truncated}, info={info}\")\n",
        "            t += DT\n",
        "            nc.log_custom_1d(\"my_custom_data\", np.array([1, 2, 3, 4, 5]), timestamp=t)\n",
        "            qpos, qvel = obs_to_joint_dict(obs, JOINT_NAMES)\n",
        "            nc.log_joint_positions(qpos, timestamp=t)\n",
        "            nc.log_joint_velocities(qvel, timestamp=t)\n",
        "            images = obs_to_imgs(obs)\n",
        "            nc.log_rgb(\"head\", images[\"head\"], timestamp=t)\n",
        "            joint_action = action_to_joint_action_dict(step.info[\"demo_action\"], JOINT_ACTUATORS)\n",
        "            nc.log_joint_target_positions(joint_action)\n",
        "            if terminated and not truncated:\n",
        "                success = True\n",
        "                print(\"Episode terminated successfully.\")\n",
        "                break\n",
        "            if truncated:\n",
        "                print(\"Episode truncated (likely time limit).\")\n",
        "                break\n",
        "    finally:\n",
        "        if record:\n",
        "            if success:\n",
        "                print(\"Episode successful ‚Üí finalizing recording...\")\n",
        "                nc.stop_recording(wait=True)\n",
        "            else:\n",
        "                print(\"Episode failed ‚Üí cancelling recording...\")\n",
        "                nc.cancel_recording()\n",
        "        env.close()\n",
        "\n",
        "    print(f\"=== Episode {episode_idx} done | success={success} ===\")\n",
        "    return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KpT8FnTTYNTK"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **(One time) Download Bigym demonstrations**\n",
        "#@markdown This cell only downloads the **Bigym demonstration data** for the **ReachTarget** Bigym environment.\n",
        "#@markdown\n",
        "#@markdown We use a **small subset** of the original Bigym demos (ReachTarget env only) for the sake of running this Notebook quickly.\n",
        "\n",
        "demo_store = DemoStore()\n",
        "\n",
        "# Override cache path so we can use e.g. Google Drive. Mount Drive first if using /content/drive/MyDrive/.\n",
        "BIGYM_DEMO_BASE_PATH = Path(\"/content/bigym_demos\")\n",
        "SUBSET_DEMO_FILENAME = \"demonstrations_subset_v2_v0.9.0\"\n",
        "demo_store._cache_path = BIGYM_DEMO_BASE_PATH / SUBSET_DEMO_FILENAME\n",
        "\n",
        "# Skip download if already cached\n",
        "if demo_store._cache_path.exists() and demo_store.cached:\n",
        "    print(\"Bigym demos already cached on disk; skipping download.\")\n",
        "else:\n",
        "    print(\"Downloading ReachTarget demo subset from Google Drive (one-time per session)...\")\n",
        "    demo_store._cache_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    subset_zip_url = \"https://drive.google.com/uc?id=1kLBOYRC489_fcMKCwFc4XOmBGIdkfsbV\"\n",
        "    subset_zip_path = BIGYM_DEMO_BASE_PATH / \"demonstrations_subset_v2_v0.9.0.zip\"\n",
        "    gdown.download(subset_zip_url, str(subset_zip_path), quiet=True)\n",
        "    with zipfile.ZipFile(subset_zip_path, \"r\") as zf:\n",
        "        zf.extractall(demo_store._cache_path.parent)\n",
        "    subset_zip_path.unlink(missing_ok=True)\n",
        "    demo_store.cached = True\n",
        "    print(\"ReachTarget demos ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QMXGhU47BWsI"
      },
      "outputs": [],
      "source": [
        "# @markdown ### **Step 0: Login to Neuracore**\n",
        "# @markdown Login to Neuracore to record data.\n",
        "# @markdown If you don't have an account, sign up for free at [neuracore.com](https://neuracore.com) before logging in.\n",
        "\n",
        "# The first time, this will prompt you to type in email and password for your account.\n",
        "# You can safely repeat this command multiple times to make sure you're logged in.\n",
        "nc.login()\n",
        "\n",
        "# Alternatively, from CLI\n",
        "# !neuracore login\n",
        "\n",
        "# For future logins, you may also save your API KEY for automatic login\n",
        "# !export NEURACORE_API_KEY=<nrc_XXXX>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jYHRBtqZBWsI"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Step 1: Connect the robot to Neuracore**\n",
        "#@markdown This step registers the H1 robot using a MuJoCo .xml configuration with your Neuracore account. Run this cell.\n",
        "#@markdown\n",
        "#@markdown **After running:** Open your Neuracore dashboard by logging into [Neuracore](https://www.neuracore.com/). Shortly after running this cell, the robot will appear among **Connected Robots** on the \"**Overview**\" page of your dashboard. You can view all registered robots on the \"**Robots**\" page.\n",
        "#@markdown\n",
        "#@markdown <br/>\n",
        "#@markdown <img src=\"https://drive.google.com/uc?id=1IdN3BYlanJsNGNsb5mi9pqFT9XD6_DJD\" width=\"800\" />\n",
        "\n",
        "BIGYM_ROOT = \"/content/bigym\"\n",
        "mjcf_path = Path(BIGYM_ROOT) / \"bigym\" / \"envs\" / \"xmls\" / \"h1\" / \"h1.xml\"\n",
        "\n",
        "robot = nc.connect_robot(\n",
        "    robot_name=\"Mujoco UnitreeH1 Example\",\n",
        "    mjcf_path=str(mjcf_path),\n",
        "    overwrite=True,\n",
        ")\n",
        "\n",
        "print(f\"Connected to robot: {robot.id}\")\n",
        "print(f\"Organisation ID: {nc.get_current_org()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLc9VW0QTBD2"
      },
      "outputs": [],
      "source": [
        "# @markdown ### **Step 2: Create a dataset**\n",
        "# @markdown Create a new dataset in Neuracore that will hold your recorded robot data. Run this cell.\n",
        "# @markdown\n",
        "# @markdown **After running:** In the dashboard, go to the \"**Data**\" page. You will see the new dataset listed. The dataset is currently empty and has no recordings in it.\n",
        "# @markdown Move to the next step to start populating the dataset with robot data.\n",
        "# @markdown\n",
        "# @markdown <br/>\n",
        "#@markdown <img src=\"https://drive.google.com/uc?id=15UDgWZmSadvPSri_nK3-Dhc9QyeJKyNy\" width=\"800\" />\n",
        "\n",
        "nc.create_dataset(\n",
        "    name=\"Getting started Bigym Example\",\n",
        "    description=\"Data collection on the Bigym simulation environments\",\n",
        ")\n",
        "print(\"Dataset created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaBimINiTDVB"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Step 3: Run simulation episodes and record data**\n",
        "#@markdown This step runs the ReachTarget environment for a number of episodes. Under the hood it uses Bigym to retrieve and replay expert actions for this task; at each step, it logs joint positions, velocities, camera images, and joint targets to Neuracore.\n",
        "#@markdown\n",
        "#@markdown **After running:** In the dataset page in your Neuracore dashboard, you will now see an item with a randomly-generated name under the \"**Recordings**\" section. You can run this cell multiple times to add more recordings to the same dataset.\n",
        "#@markdown\n",
        "#@markdown <br/>\n",
        "#@markdown <img src=\"https://drive.google.com/uc?id=1w-wOH81_jdJsX5XvKZU4t7ugkTTkaibb\" width=\"800\" />\n",
        "\n",
        "NUM_EPISODES = 1\n",
        "RECORD = True\n",
        "\n",
        "success_count = 0\n",
        "try:\n",
        "    for episode_idx in range(NUM_EPISODES):\n",
        "        success = run_episode(\n",
        "            episode_idx=episode_idx, record=RECORD, demo_store=demo_store\n",
        "        )\n",
        "        if success:\n",
        "            success_count += 1\n",
        "            print(f\"Successful demos: {success_count}/{episode_idx + 1}\")\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nInterrupted by user.\")\n",
        "    if RECORD:\n",
        "        nc.cancel_recording()\n",
        "finally:\n",
        "    print(f\"\\nFinished running {NUM_EPISODES} episodes ‚Üí {success_count} succeeded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqB_Zh4Qbcaa"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Step 4: Visualize collected data**\n",
        "#@markdown On the \"**Data**\" page of your Neuracore dashboard, click on the latest recording to open the **data visualizer**.\n",
        "#@markdown\n",
        "#@markdown Here, you can replay the episode and view the URDF animation, the RGB images, and the joint recordings.\n",
        "#@markdown\n",
        "#@markdown <br/>\n",
        "#@markdown\n",
        "#@markdown <img src=\"https://drive.google.com/uc?id=1TRhdLBwUPQTLlquxCk-XERl7kErfDer5\" width=\"800\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iQtoqmzpYLM"
      },
      "outputs": [],
      "source": [
        "# @markdown ### **Step 5: Retrieve dataset from Neuracore cloud to a local client**\n",
        "# @markdown You can pull data from Neuracore using `nc.get_dataset(\"my dataset\")`.\n",
        "# @markdown\n",
        "# @markdown Run this cell to retrieve the previously recorded dataset \"Getting started Bigym Example\" into this notebook client.\n",
        "# @markdown You can then visualize the data locally, or train your models with it.\n",
        "\n",
        "from neuracore_types import DataType, RobotDataSpec\n",
        "import imageio\n",
        "from IPython.display import Video, display\n",
        "\n",
        "DATASET_NAME = \"Getting started Bigym Example\"\n",
        "dataset = nc.get_dataset(DATASET_NAME)\n",
        "\n",
        "data_types_to_sync = [DataType.JOINT_POSITIONS, DataType.RGB_IMAGES]\n",
        "robot_data_spec: RobotDataSpec = {}\n",
        "for robot_id in dataset.robot_ids:\n",
        "    full_spec = dataset.get_full_data_spec(robot_id)\n",
        "    robot_data_spec[robot_id] = {\n",
        "        dt: full_spec[dt] for dt in data_types_to_sync if dt in full_spec\n",
        "    }\n",
        "\n",
        "synced = dataset.synchronize(frequency=FREQUENCY, robot_data_spec=robot_data_spec)\n",
        "print(f\"Dataset '{DATASET_NAME}': {len(dataset)} episodes\")\n",
        "\n",
        "# First episode summary + video from head camera\n",
        "first_ep = synced[0]\n",
        "steps_list = list(first_ep)\n",
        "\n",
        "print(f\"First episode: {len(steps_list)} steps, duration {first_ep.end_time - first_ep.start_time:.2f} s\")\n",
        "\n",
        "frames = [step[DataType.RGB_IMAGES][\"head\"].frame for step in steps_list]\n",
        "video_path = \"/tmp/first_episode.mp4\"\n",
        "imageio.mimsave(video_path, frames, fps=FREQUENCY)\n",
        "print(\"First episode video (head camera):\")\n",
        "display(Video(video_path, embed=True, width=420))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s49c6xH4SYaT"
      },
      "source": [
        "### **Step 6: Train a model on your dataset**\n",
        "\n",
        "1. ‚òÅÔ∏è **Cloud training (using Neuracore credits)**\n",
        "\n",
        "   You can start a training job on **Neuracore's cloud** in two ways:\n",
        "\n",
        "   - **From the dashboard UI**: go to the **Training** page on your [web dashboard](https://www.neuracore.com/), click **+ New training job**, select your dataset, algorithm, and resources, then launch.\n",
        "   - **From Python**: using `nc.start_training_run(...)`. For example:\n",
        "\n",
        "     ```python\n",
        "     job_data = nc.start_training_run(\n",
        "       name=\"MyTrainingJob\",\n",
        "       dataset_name=\"Getting started Bigym Example\",\n",
        "       algorithm_name=\"diffusion_policy\",\n",
        "       num_gpus=1,\n",
        "       frequency=50,\n",
        "       ...\n",
        "     )\n",
        "     ```\n",
        "\n",
        "2. üíª **Local training**\n",
        "\n",
        "   To train **locally** on your own GPU, call the training script directly as documented in the [training docs](https://github.com/NeuracoreAI/neuracore/blob/main/docs/training.md). Here's a minimal example:\n",
        "\n",
        "   ```bash\n",
        "   python -m neuracore.ml.train algorithm=diffusion_policy dataset_name=\"Getting started Bigym Example\"\n",
        "   ```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe41MTJLbmE9"
      },
      "source": [
        "### **Step 7: Model deployment and inference**\n",
        "\n",
        "After your training job has finished, you can **use the trained model for inference** either **locally** or remotely via a **cloud endpoint**.\n",
        "\n",
        "1. ‚òÅÔ∏è **Cloud inference (using Neuracore credits)**\n",
        "\n",
        "   To run inference on Neuracore's servers:\n",
        "\n",
        "   - Go to the **Endpoints** tab on your [web dashboard](https://www.neuracore.com/) and create a deployment endpoint for a trained model.\n",
        "   - Once the endpoint is **active**, use `nc.policy_remote_server(...)` from Python:\n",
        "\n",
        "     ```python\n",
        "     try:\n",
        "         policy = nc.policy_remote_server(\"MyEndpointName\")\n",
        "         predictions = policy.predict(timeout=5)\n",
        "     except nc.EndpointError:\n",
        "         print(\"Endpoint not available. Please start it at neuracore.com/dashboard/endpoints\")\n",
        "     ```\n",
        "\n",
        "2. üíª **Local inference (run model on local GPU)**\n",
        "\n",
        "   You can load a trained model locally via `policy.predict(...)` (see the [tutorial](https://github.com/NeuracoreAI/neuracore/blob/main/docs/tutorial.md#model-inference) and [local endpoint examples](https://github.com/NeuracoreAI/neuracore/tree/main/examples)):\n",
        "\n",
        "   - **By training run name** (pull model from Neuracore):\n",
        "\n",
        "     ```python\n",
        "     from neuracore_types import DataSpec, DataType\n",
        "\n",
        "     MODEL_INPUT_ORDER: DataSpec = {\n",
        "        DataType.JOINT_POSITIONS: JOINT_NAMES[:-1],\n",
        "        DataType.RGB_IMAGES: CAMERA_NAMES,\n",
        "     }\n",
        "\n",
        "     MODEL_OUTPUT_ORDER: DataSpec = {\n",
        "        DataType.JOINT_TARGET_POSITIONS: JOINT_ACTUATORS,\n",
        "     }\n",
        "\n",
        "     policy = nc.policy(\n",
        "         train_run_name=\"MyTrainingJob\",\n",
        "         model_input_order=MODEL_INPUT_ORDER,\n",
        "         model_output_order=MODEL_OUTPUT_ORDER,\n",
        "     )\n",
        "\n",
        "     predictions = policy.predict(timeout=5)\n",
        "     ```\n",
        "\n",
        "   - **By local model file**:\n",
        "\n",
        "     ```python\n",
        "     policy = nc.policy(\n",
        "         model_file=\"/path/to/model.nc.zip\",\n",
        "         model_input_order=MODEL_INPUT_ORDER,\n",
        "         model_output_order=MODEL_OUTPUT_ORDER,\n",
        "     )\n",
        "     predictions = policy.predict(timeout=5)\n",
        "     ```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}